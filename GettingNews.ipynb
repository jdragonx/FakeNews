{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painted-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subsequent-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nervous-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\r"
     ]
    }
   ],
   "source": [
    "newsData = list()\n",
    "for i in range(1,647):\n",
    "    url = \"https://www.politifact.com/factchecks/list/?page=\"+str(i)\n",
    "    page = requests.get(url,headers=head)\n",
    "    print(page,end=\"\\r\")\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    titles = soup.find_all(class_ = \"m-statement--is-medium\")\n",
    "    for title in titles:\n",
    "        newsName = title.find(class_=\"m-statement__name\").text[1:-1]\n",
    "        newsDesc = title.find(class_=\"m-statement__desc\").text[1:-1]\n",
    "        newsQuote = title.find(class_=\"m-statement__quote\").text[2:-2]\n",
    "        newsRate = title.find(class_=\"m-statement__meter\").div.picture.img[\"alt\"]\n",
    "        newsRate = \"mostly-false\" if newsRate==\"barely-true\" else newsRate\n",
    "        news = [newsName+\" \"+newsDesc+\" \"+newsQuote,newsRate]\n",
    "        newsData.append(news)\n",
    "        \n",
    "df_politifact = pd.DataFrame(newsData,columns=['News','Rating'])\n",
    "df_politifact.to_csv('data/politifact.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electric-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\r"
     ]
    }
   ],
   "source": [
    "newsData = list()\n",
    "for i in range(221,1366):\n",
    "    url = \"https://www.snopes.com/fact-check/page/{}/\".format(i)\n",
    "    page = requests.get(url,headers=head)\n",
    "    print(page,end=\"\\r\")\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    titles = soup.find_all(class_=\"stretched-link\")\n",
    "    for title in titles[:-5]:\n",
    "        checkUrl = title[\"href\"]\n",
    "        checkPage = requests.get(checkUrl,headers=head)\n",
    "        checkSoup = BeautifulSoup(checkPage.text, \"html.parser\")\n",
    "        if (checkSoup.find(class_=\"claim-text card-body\") is None):\n",
    "            continue\n",
    "        newsQuote = checkSoup.find(class_=\"claim-text card-body\").text.replace('\\n','').replace('\\t','')[:-1]\n",
    "        if (checkSoup.find(string=\"Rating\") is None):\n",
    "            continue\n",
    "        newsRate = checkSoup.find(string=\"Rating\").parent.parent.parent.a['href']\n",
    "        newsRate = newsRate.replace('https://www.snopes.com/fact-check/rating/','').replace(\"/\",\"\")\n",
    "        news = [newsQuote,newsRate]\n",
    "        newsData.append(news)\n",
    "\n",
    "df_snopes = pd.DataFrame(newsData,columns=['News','Rating'])\n",
    "df_snopes.to_csv('data/snopes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "catholic-papua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\r"
     ]
    }
   ],
   "source": [
    "newsData = list()\n",
    "for i in range(83,230):\n",
    "    url = \"https://www.truthorfiction.com/category/fact-checks/page/{}/\".format(i)\n",
    "    page = requests.get(url,headers=head)\n",
    "    print(page,end=\"\\r\")\n",
    "    if(str(page)[-5:-4]=='5'):\n",
    "        i = i-1\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    titles = soup.find_all(\"h2\")[:-1]\n",
    "    for title in titles:\n",
    "        checkUrl = title.a[\"href\"]\n",
    "        checkPage = requests.get(checkUrl,headers=head)\n",
    "        checkSoup = BeautifulSoup(checkPage.text, \"html.parser\")\n",
    "        if (checkSoup.find(class_=\"claim-description\") is None):\n",
    "            continue\n",
    "        newsQuote = checkSoup.find(class_=\"claim-description\").text\n",
    "        if (checkSoup.find(class_=\"rating-description\") is None):\n",
    "            continue\n",
    "        newsRate = checkSoup.find(class_=\"rating-description\").span.text\n",
    "        news = [newsQuote,newsRate]\n",
    "        newsData.append(news)\n",
    "\n",
    "df_truthorfiction = pd.DataFrame(newsData,columns=['News','Rating'])\n",
    "df_truthorfiction.to_csv('data/truthorfiction.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "human-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\r"
     ]
    }
   ],
   "source": [
    "newsData = list()\n",
    "for i in range(76,121):\n",
    "    url = \"https://checkyourfact.com/page/{}/\".format(i)\n",
    "    page = requests.get(url,headers=head)\n",
    "    print(page,end=\"\\r\")\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    titles = soup.find(\"articles\").find_all(\"a\")\n",
    "    for title in titles:\n",
    "        checkUrl = \"https://checkyourfact.com\"+title['href']\n",
    "        checkPage = requests.get(checkUrl,headers=head)\n",
    "        checkSoup = BeautifulSoup(checkPage.text, \"html.parser\")\n",
    "        if (checkSoup.p.text is None):\n",
    "            continue\n",
    "        newsQuote = checkSoup.p.text\n",
    "        newsRate = checkSoup.find(\"strong\")\n",
    "        if (newsRate is None):\n",
    "            newsRate = checkSoup.find(\"b\")\n",
    "        if (newsRate is None):\n",
    "            continue\n",
    "        newsRate = newsRate.text[9:]\n",
    "        news = [newsQuote,newsRate]\n",
    "        newsData.append(news)\n",
    "\n",
    "df_checkyourfact = pd.DataFrame(newsData,columns=['News','Rating'])\n",
    "df_checkyourfact.to_csv('data/checkyourfact.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
